model_name_or_path: yentinglin/Taiwan-LLM-7B-v2.1-chat
template: llama2
infer_backend: vllm
vllm_enforce_eager: true
vllm_maxlen: 4096
