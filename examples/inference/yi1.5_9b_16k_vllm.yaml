model_name_or_path: 01-ai/Yi-1.5-9B-Chat-16K
template: yi
infer_backend: vllm
vllm_enforce_eager: true
# vllm_gpu_util: 0.8
vllm_maxlen: 16384